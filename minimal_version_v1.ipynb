{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLUFPzSl212G",
        "colab_type": "code",
        "outputId": "97f0bf42-3c2c-42a9-b9a1-be7f78b3454c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDh3j19J4FZz",
        "colab_type": "code",
        "outputId": "fbb57482-3cd2-4846-c570-6e1e5a71f7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "!pip install wfdb\n",
        "!pip install mne\n",
        "#!pip install nitime\n",
        "#!pip install nolds"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/96/c2200539fdf4f087e14d30ed62a66544b6f441196bcb8ecc7a29ec6503b9/wfdb-2.2.1.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.1MB/s \n",
            "\u001b[?25hCollecting nose>=1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.17.4)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.1.2)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.3.3)\n",
            "Requirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->wfdb) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn>=0.0->wfdb) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->wfdb) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->wfdb) (42.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn>=0.0->wfdb) (0.14.0)\n",
            "Building wheels for collected packages: wfdb\n",
            "  Building wheel for wfdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wfdb: filename=wfdb-2.2.1-cp36-none-any.whl size=100368 sha256=3396c1c3aad3a9171e94f6942f51da96654533e95531c4e5285d96286b6d3e77\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a9/00/0078d26b0c15b31be0001af8eb659496709c361c69641303f1\n",
            "Successfully built wfdb\n",
            "Installing collected packages: nose, wfdb\n",
            "Successfully installed nose-1.3.7 wfdb-2.2.1\n",
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/7c/ad1b52a3fdd4be8f55e183f1eff7d76f48cd1bee83c5630f9c26770e032e/mne-0.19.2-py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 372kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.17.4)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.3.3)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.19.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BitRtTGT4Qyb",
        "colab_type": "code",
        "outputId": "69ec6d21-5897-4ec6-ca80-03117fb212fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "\n",
        "!pip install git+https://github.com/forrestbao/pyeeg.git\n",
        "!pip install git+https://github.com/talhaanwarch/entropy.git\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-_wmbl5uu\n",
            "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-_wmbl5uu\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyeeg==0.4.4) (1.17.4)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28121 sha256=9cebff407caa76389d41e95b23796cce5f5dc3cbc78bb02cc7f58fa9f29945a5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sixn_xws/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "Successfully installed pyeeg-0.4.4\n",
            "Collecting git+https://github.com/talhaanwarch/entropy.git\n",
            "  Cloning https://github.com/talhaanwarch/entropy.git to /tmp/pip-req-build-9cscoogx\n",
            "  Running command git clone -q https://github.com/talhaanwarch/entropy.git /tmp/pip-req-build-9cscoogx\n",
            "Building wheels for collected packages: entropy\n",
            "  Building wheel for entropy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for entropy: filename=entropy-0.1.1-cp36-none-any.whl size=15447 sha256=1c544d08e9f75c7efe2f101e6a05780e1a03c009fceeaa237aab1eb0e549e8ae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vqblegaz/wheels/79/43/63/3fa9c8c5f03fe3a78d71c1aeedca9577f2f32fb2156ff9ecf8\n",
            "Successfully built entropy\n",
            "Installing collected packages: entropy\n",
            "Successfully installed entropy-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0d2K51X2255",
        "colab_type": "code",
        "outputId": "43e033fe-06fd-4f17-e310-66a1def05714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/schizophrenia16"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/schizophrenia16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4VF2wMU2a9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from glob import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65gRe7Tm2a9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MaxAbsScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "841F2uFr2a9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrcQgBt6_2M4",
        "colab_type": "text"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfTkTDcJ2a94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HC_path=glob('norm/*.eea')\n",
        "SZ_path=glob('sch/*.eea')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6X4qK34EicD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import signal\n",
        "nyq = 0.5 * 128\n",
        "l=0.3\n",
        "low = l / nyq\n",
        "high = 30 / nyq\n",
        "b, a = signal.butter(4, [low,high], 'band')\n",
        "from sklearn.decomposition import PCA\n",
        "ch=14\n",
        "pca=PCA(ch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8p6dZ1T2a97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HC=[]#trialxsample x channels\n",
        "for i in HC_path:\n",
        "    data=np.loadtxt(i)\n",
        "    data=data.reshape(-1,16).T #datapoints x columns\n",
        "    # Tranpose is taken becz data should be columns into sample points\n",
        "    data=signal.filtfilt(b, a, data) \n",
        "    data=pca.fit_transform(data.T).T\n",
        "    data=data.reshape(ch,-1,512).T\n",
        "    data=np.swapaxes(data,0,1)\n",
        "    HC.append(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDG2yOdT2a-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SZ=[]\n",
        "for i in SZ_path:\n",
        "    data=np.loadtxt(i)\n",
        "    data=data.reshape(-1,16).T #datapoints x columns\n",
        "    # Tranpose is taken becz data should be columns into sample points\n",
        "    data=pca.fit_transform(data.T).T\n",
        "    data=data.reshape(ch,-1,512).T\n",
        "    data=np.swapaxes(data,0,1)\n",
        "    SZ.append(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAPj73rQ2a-D",
        "colab_type": "code",
        "outputId": "3c85be9b-fd29-4c70-bb4d-1bd824e2041f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "HC[0].shape,SZ[0].shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15, 512, 14), (15, 512, 14))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ryNeW52a-G",
        "colab_type": "text"
      },
      "source": [
        "# Feature Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8C0CXGb2a-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "import pyeeg\n",
        "from entropy import *\n",
        "def mean(data):\n",
        "    return np.mean(data,axis=0)\n",
        "    \n",
        "def std(data):\n",
        "    return np.std(data,axis=0)\n",
        "\n",
        "def ptp(data):\n",
        "    return np.ptp(data,axis=0)\n",
        "\n",
        "def var(data):\n",
        "        return np.var(data,axis=0)\n",
        "\n",
        "def minim(data):\n",
        "      return np.min(data,axis=0)\n",
        "\n",
        "\n",
        "def maxim(data):\n",
        "      return np.max(data,axis=0)\n",
        "\n",
        "\n",
        "def mean_square(data):\n",
        "      return np.mean(data**2,axis=0)\n",
        "\n",
        "def rms(data): #root mean square\n",
        "      return  np.sqrt(np.mean(data**2,axis=0))  \n",
        "\n",
        "def abs_diffs_signal(data):\n",
        "    return np.sum(np.abs(np.diff(data,axis=0)),axis=0)\n",
        "\n",
        "\n",
        "def skewness(data):\n",
        "    return stats.skew(data,axis=0)\n",
        "\n",
        "def kurtosis(data):\n",
        "    return stats.kurtosis(data,axis=0)\n",
        "\n",
        "def zero_crossing(data):\n",
        "    return np.argmax(np.diff(np.sign(data),axis=0),axis=0)\n",
        "\n",
        "def app_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(app_entropy(i, order=2, metric='chebyshev'))\n",
        "    return np.array(result)\n",
        "\n",
        "def perm_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(perm_entropy(i, order=3, normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def svd_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(svd_entropy(i, order=3, delay=1, normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def spectral_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(spectral_entropy(i, 100, method='welch', normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def sample_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(sample_entropy(i, order=2, metric='chebyshev'))\n",
        "    return np.array(result)\n",
        "\n",
        "\n",
        "def katz(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(katz_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "def higuchi(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(higuchi_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "\n",
        "def petrosian(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(petrosian_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "def autogressiveModelParameters(data):\n",
        "    feature = []\n",
        "    for i in data.T:\n",
        "        coeff, sig = alg.AR_est_YW(i, order=5)\n",
        "        feature.append(np.mean(coeff))\n",
        "    return np.array(feature)\n",
        "\n",
        "def teager(x):\n",
        "    for i in range(len(x)-1):\n",
        "        return x[i]**2 - (x[i-1]*x[i+1])\n",
        "\n",
        "\n",
        "        \n",
        "def hjorth_mobility(data):\n",
        "    return np.divide(np.std(np.diff(data,axis=0),axis=0),np.std(data,axis=0))\n",
        "\n",
        "def hjorth_complexity(data):\n",
        "    return np.divide(hjorth_mobility(np.diff(data,axis=0)),  hjorth_mobility(data))      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def concatenate_features(data):\n",
        "    return np.concatenate((mean(data),std(data),ptp(data),var(data),minim(data),maxim(data),\n",
        "                          mean_square(data),rms(data),abs_diffs_signal(data),\n",
        "                          skewness(data),kurtosis(data),zero_crossing(data),\n",
        "                          app_epy(data),perm_epy(data),svd_epy(data),spectral_epy(data),sample_epy(data),\n",
        "                          katz(data),higuchi(data),petrosian(data),\n",
        "                          hjorth_mobility(data),hjorth_complexity(data)),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cGUc_pg2a-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features1=[]\n",
        "for f in HC:\n",
        "    feature=[]\n",
        "    for i in f:\n",
        "        feature.append(concatenate_features(i))\n",
        "    features1.append(np.mean(np.array(feature),axis=0))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx7_uedy2a-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features2=[]\n",
        "for f in SZ:\n",
        "    feature=[]\n",
        "    for i in f:\n",
        "        feature.append(concatenate_features(i))\n",
        "    features2.append(np.mean(np.array(feature),axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJvSX8Q52a-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=np.array(features1)        \n",
        "x2=np.array(features2)      \n",
        "\n",
        "X_all=np.concatenate((x1,x2),axis=0)\n",
        "y_all=np.concatenate(((np.zeros(x1.shape[0])),(np.ones(x2.shape[0]))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0dfDFRo2a-U",
        "colab_type": "code",
        "outputId": "597a82b4-f198-47af-ac84-eedc335489ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "x1.shape,x2.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((39, 308), (45, 308))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92vi6x2f2a-Y",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgzccMU72a-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,test_size=0.3, shuffle=True,random_state=42,stratify=y_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Csl0t32a-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aHqVq1RG2a-g",
        "colab_type": "code",
        "outputId": "9cbd39f3-38e6-4c8c-be25-b67d762c4fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "\n",
        "clf=SVC(kernel='rbf')\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('accuracy is ',accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.92      0.96        12\n",
            "         1.0       0.93      1.00      0.97        14\n",
            "\n",
            "    accuracy                           0.96        26\n",
            "   macro avg       0.97      0.96      0.96        26\n",
            "weighted avg       0.96      0.96      0.96        26\n",
            "\n",
            "accuracy is  0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g76krwyJWXQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('X_schizo_1',X_all)\n",
        "np.save('y_schizo_1',y_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGNXUlwTq9kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}